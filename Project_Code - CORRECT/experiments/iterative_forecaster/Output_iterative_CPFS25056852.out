/zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/experiments/iterative_forecaster

Experiment directories created under: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS

Model Configuration:
  hidden_size: 24
  dropout: 0.25
  batch_size: 7392
  epochs: 100
  patience: 15
  learning_rate: 0.001
  week_steps: 672
  warmup_length: 672
  threshold: 13.0
  window_size: 100
  quick_mode: False
  objective_function: mae_loss
  use_time_features: False
  use_cumulative_features: True

Initializing trainer...

üñ•Ô∏è  Device Information:
   Using device: cpu
   CUDA not available, using CPU
==================================================
Using features: ['vst_raw_feature', 'temperature', 'rainfall']

Loading data for station 21006846...

Loading data for station 21006846...

Input Features Summary:
----------------------
Using features from:
  - Primary station:
    * vst_raw_feature
    * temperature
    * rainfall

Feature engineering settings:
  - Using time features: False
  - Using cumulative features: True
  - Using lagged features: False
----------------------


Handling NaN values:
  - Temperature: Forward fill, backward fill, then 30-day aggregation
  - Rainfall: Fill NaN with -1
  - vst_raw_feature: Fill NaN with -1
  - Target (vst_raw): Keep NaN values (handled in loss calculation)

Adding cumulative features...
  - Added cumulative rainfall features

All available feature columns (11): ['vst_raw_feature', 'temperature', 'rainfall', 'station_46_rain_1hour', 'station_46_rain_7hour', 'station_46_rain_48hour', 'station_46_rain_90hour', 'station_46_rain_1month', 'station_46_rain_3months', 'station_46_rain_6months', 'station_46_rain_1year']
Initializing model with input size: 11

Features in the model: Index(['vst_raw_feature', 'temperature', 'rainfall', 'vst_raw',
       'station_46_rain_1hour', 'station_46_rain_7hour',
       'station_46_rain_48hour', 'station_46_rain_90hour',
       'station_46_rain_1month', 'station_46_rain_3months',
       'station_46_rain_6months', 'station_46_rain_1year'],
      dtype='object')

Total features after engineering: 12

NaN values in data splits (after handling):
----------------------------------------

Training data:
  vst_raw: 73463 NaN values (17.85%)

Validation data:
  vst_raw: 5 NaN values (0.01%)

Test data:

Split Summary:
Training period: 2010 - 2021
Validation period: 2022 - 2023
Test year: 2024

Data shapes:
Total data: (517240, 12)
Train data: (411488, 12)
Validation data: (70078, 12)
Test data: (35136, 12)

No synthetic errors injected.

Training model...

Preparing training and validation data...

Preparing sequences:
Input DataFrame shape: (411488, 12)
Using all available features: 11 features
Features: ['vst_raw_feature', 'temperature', 'rainfall', 'station_46_rain_1hour', 'station_46_rain_7hour', 'station_46_rain_48hour', 'station_46_rain_90hour', 'station_46_rain_1month', 'station_46_rain_3months', 'station_46_rain_6months', 'station_46_rain_1year']
Features DataFrame shape: (411488, 11)
Target DataFrame shape: (411488, 1)
Fitted scalers on 338025 valid target points
Scaled features shape: (411488, 11)

NaN values in final tensors:
--------------------------
Target: 73463 NaN values (17.85%)
Prepared tensors - x_shape: torch.Size([1, 411488, 11]), y_shape: torch.Size([1, 411488, 1])

Preparing sequences:
Input DataFrame shape: (70078, 12)
Using all available features: 11 features
Features: ['vst_raw_feature', 'temperature', 'rainfall', 'station_46_rain_1hour', 'station_46_rain_7hour', 'station_46_rain_48hour', 'station_46_rain_90hour', 'station_46_rain_1month', 'station_46_rain_3months', 'station_46_rain_6months', 'station_46_rain_1year']
Features DataFrame shape: (70078, 11)
Target DataFrame shape: (70078, 1)
Scaled features shape: (70078, 11)

NaN values in final tensors:
--------------------------
Target: 5 NaN values (0.01%)
Prepared tensors - x_shape: torch.Size([1, 70078, 11]), y_shape: torch.Size([1, 70078, 1])

Training data shapes:
x_train: torch.Size([1, 411488, 11])
y_train: torch.Size([1, 411488, 1])
x_val: torch.Size([1, 70078, 11])
y_val: torch.Size([1, 70078, 1])

Training configuration:
Total samples: 411488
Batch size: 7392
Number of batches per epoch: 56

Epoch 1/100 - Train Loss: 0.777892, Val Loss: 0.594110
New best validation loss: inf

Epoch 2/100 - Train Loss: 0.628629, Val Loss: 0.415511
New best validation loss: 0.594110

Epoch 3/100 - Train Loss: 0.546574, Val Loss: 0.369738
New best validation loss: 0.415511

Epoch 4/100 - Train Loss: 0.522169, Val Loss: 0.349749
New best validation loss: 0.369738

Epoch 5/100 - Train Loss: 0.498634, Val Loss: 0.314393
New best validation loss: 0.349749

Epoch 6/100 - Train Loss: 0.471882, Val Loss: 0.266213
New best validation loss: 0.314393

Epoch 7/100 - Train Loss: 0.446343, Val Loss: 0.215229
New best validation loss: 0.266213

Epoch 8/100 - Train Loss: 0.431473, Val Loss: 0.207238
New best validation loss: 0.215229

Epoch 9/100 - Train Loss: 0.419982, Val Loss: 0.175276
New best validation loss: 0.207238

Epoch 10/100 - Train Loss: 0.413160, Val Loss: 0.177102
Patience: 1/15

Epoch 11/100 - Train Loss: 0.399820, Val Loss: 0.172307
New best validation loss: 0.175276

Epoch 12/100 - Train Loss: 0.401920, Val Loss: 0.159580
New best validation loss: 0.172307

Epoch 13/100 - Train Loss: 0.393987, Val Loss: 0.159854
Patience: 1/15

Epoch 14/100 - Train Loss: 0.387544, Val Loss: 0.161604
Patience: 2/15

Epoch 15/100 - Train Loss: 0.382283, Val Loss: 0.161938
Patience: 3/15

Epoch 16/100 - Train Loss: 0.381098, Val Loss: 0.149814
New best validation loss: 0.159580

Epoch 17/100 - Train Loss: 0.379026, Val Loss: 0.154255
Patience: 1/15

Epoch 18/100 - Train Loss: 0.375663, Val Loss: 0.147994
New best validation loss: 0.149814

Epoch 19/100 - Train Loss: 0.378135, Val Loss: 0.151338
Patience: 1/15

Epoch 20/100 - Train Loss: 0.376962, Val Loss: 0.140484
New best validation loss: 0.147994

Epoch 21/100 - Train Loss: 0.377229, Val Loss: 0.136081
New best validation loss: 0.140484

Epoch 22/100 - Train Loss: 0.369505, Val Loss: 0.144947
Patience: 1/15

Epoch 23/100 - Train Loss: 0.370424, Val Loss: 0.135964
New best validation loss: 0.136081

Epoch 24/100 - Train Loss: 0.364848, Val Loss: 0.145071
Patience: 1/15

Epoch 25/100 - Train Loss: 0.362529, Val Loss: 0.135457
New best validation loss: 0.135964

Epoch 26/100 - Train Loss: 0.359966, Val Loss: 0.139669
Patience: 1/15

Epoch 27/100 - Train Loss: 0.346579, Val Loss: 0.134038
New best validation loss: 0.135457

Epoch 28/100 - Train Loss: 0.346589, Val Loss: 0.133389
New best validation loss: 0.134038

Epoch 29/100 - Train Loss: 0.344887, Val Loss: 0.141813
Patience: 1/15

Epoch 30/100 - Train Loss: 0.340968, Val Loss: 0.137062
Patience: 2/15

Epoch 31/100 - Train Loss: 0.339548, Val Loss: 0.122423
New best validation loss: 0.133389

Epoch 32/100 - Train Loss: 0.333236, Val Loss: 0.121533
New best validation loss: 0.122423

Epoch 33/100 - Train Loss: 0.326323, Val Loss: 0.123827
Patience: 1/15

Epoch 34/100 - Train Loss: 0.328282, Val Loss: 0.117040
New best validation loss: 0.121533

Epoch 35/100 - Train Loss: 0.315364, Val Loss: 0.120759
Patience: 1/15

Epoch 36/100 - Train Loss: 0.323334, Val Loss: 0.109051
New best validation loss: 0.117040

Epoch 37/100 - Train Loss: 0.315175, Val Loss: 0.120716
Patience: 1/15

Epoch 38/100 - Train Loss: 0.317862, Val Loss: 0.117790
Patience: 2/15

Epoch 39/100 - Train Loss: 0.313715, Val Loss: 0.113383
Patience: 3/15

Epoch 40/100 - Train Loss: 0.304109, Val Loss: 0.114746
Patience: 4/15

Epoch 41/100 - Train Loss: 0.309059, Val Loss: 0.105551
New best validation loss: 0.109051

Epoch 42/100 - Train Loss: 0.310868, Val Loss: 0.116714
Patience: 1/15

Epoch 43/100 - Train Loss: 0.308076, Val Loss: 0.120566
Patience: 2/15

Epoch 44/100 - Train Loss: 0.300631, Val Loss: 0.098994
New best validation loss: 0.105551

Epoch 45/100 - Train Loss: 0.296849, Val Loss: 0.113183
Patience: 1/15

Epoch 46/100 - Train Loss: 0.308155, Val Loss: 0.111973
Patience: 2/15

Epoch 47/100 - Train Loss: 0.297265, Val Loss: 0.104471
Patience: 3/15

Epoch 48/100 - Train Loss: 0.296739, Val Loss: 0.110191
Patience: 4/15

Epoch 49/100 - Train Loss: 0.304934, Val Loss: 0.104303
Patience: 5/15

Epoch 50/100 - Train Loss: 0.291995, Val Loss: 0.106079
Patience: 6/15

Epoch 51/100 - Train Loss: 0.292741, Val Loss: 0.102319
Patience: 7/15

Epoch 52/100 - Train Loss: 0.290564, Val Loss: 0.111522
Patience: 8/15

Epoch 53/100 - Train Loss: 0.294488, Val Loss: 0.091861
New best validation loss: 0.098994

Epoch 54/100 - Train Loss: 0.288465, Val Loss: 0.093130
Patience: 1/15

Epoch 55/100 - Train Loss: 0.297166, Val Loss: 0.113486
Patience: 2/15

Epoch 56/100 - Train Loss: 0.295695, Val Loss: 0.095837
Patience: 3/15

Epoch 57/100 - Train Loss: 0.292164, Val Loss: 0.090883
New best validation loss: 0.091861

Epoch 58/100 - Train Loss: 0.279458, Val Loss: 0.084687
New best validation loss: 0.090883

Epoch 59/100 - Train Loss: 0.286456, Val Loss: 0.099335
Patience: 1/15

Epoch 60/100 - Train Loss: 0.285970, Val Loss: 0.083800
New best validation loss: 0.084687

Epoch 61/100 - Train Loss: 0.275249, Val Loss: 0.085981
Patience: 1/15

Epoch 62/100 - Train Loss: 0.270573, Val Loss: 0.082320
New best validation loss: 0.083800

Epoch 63/100 - Train Loss: 0.278157, Val Loss: 0.090687
Patience: 1/15

Epoch 64/100 - Train Loss: 0.279195, Val Loss: 0.085038
Patience: 2/15

Epoch 65/100 - Train Loss: 0.272464, Val Loss: 0.090449
Patience: 3/15

Epoch 66/100 - Train Loss: 0.274907, Val Loss: 0.082329
Patience: 4/15

Epoch 67/100 - Train Loss: 0.273952, Val Loss: 0.087062
Patience: 5/15

Epoch 68/100 - Train Loss: 0.275041, Val Loss: 0.089513
Patience: 6/15

Epoch 69/100 - Train Loss: 0.268202, Val Loss: 0.087936
Patience: 7/15

Epoch 70/100 - Train Loss: 0.269866, Val Loss: 0.084230
Patience: 8/15

Epoch 71/100 - Train Loss: 0.261628, Val Loss: 0.077891
New best validation loss: 0.082320

Epoch 72/100 - Train Loss: 0.268863, Val Loss: 0.085598
Patience: 1/15

Epoch 73/100 - Train Loss: 0.260736, Val Loss: 0.087799
Patience: 2/15

Epoch 74/100 - Train Loss: 0.270523, Val Loss: 0.089522
Patience: 3/15

Epoch 75/100 - Train Loss: 0.265862, Val Loss: 0.082775
Patience: 4/15

Epoch 76/100 - Train Loss: 0.260504, Val Loss: 0.091922
Patience: 5/15

Epoch 77/100 - Train Loss: 0.256394, Val Loss: 0.080319
Patience: 6/15

Epoch 78/100 - Train Loss: 0.258283, Val Loss: 0.086514
Patience: 7/15

Epoch 79/100 - Train Loss: 0.256732, Val Loss: 0.081257
Patience: 8/15

Epoch 80/100 - Train Loss: 0.255855, Val Loss: 0.076140
New best validation loss: 0.077891

Epoch 81/100 - Train Loss: 0.245617, Val Loss: 0.075916
New best validation loss: 0.076140

Epoch 82/100 - Train Loss: 0.257130, Val Loss: 0.077370
Patience: 1/15

Epoch 83/100 - Train Loss: 0.253757, Val Loss: 0.078887
Patience: 2/15

Epoch 84/100 - Train Loss: 0.252711, Val Loss: 0.082618
Patience: 3/15

Epoch 85/100 - Train Loss: 0.253918, Val Loss: 0.078205
Patience: 4/15

Epoch 86/100 - Train Loss: 0.254508, Val Loss: 0.075693
New best validation loss: 0.075916

Epoch 87/100 - Train Loss: 0.249927, Val Loss: 0.072653
New best validation loss: 0.075693

Epoch 88/100 - Train Loss: 0.246758, Val Loss: 0.080874
Patience: 1/15

Epoch 89/100 - Train Loss: 0.243569, Val Loss: 0.082829
Patience: 2/15

Epoch 90/100 - Train Loss: 0.245703, Val Loss: 0.075047
Patience: 3/15

Epoch 91/100 - Train Loss: 0.239676, Val Loss: 0.075122
Patience: 4/15

Epoch 92/100 - Train Loss: 0.240908, Val Loss: 0.073661
Patience: 5/15

Epoch 93/100 - Train Loss: 0.240002, Val Loss: 0.073707
Patience: 6/15

Epoch 94/100 - Train Loss: 0.241370, Val Loss: 0.083489
Patience: 7/15

Epoch 95/100 - Train Loss: 0.234511, Val Loss: 0.067354
New best validation loss: 0.072653

Epoch 96/100 - Train Loss: 0.237020, Val Loss: 0.072226
Patience: 1/15

Epoch 97/100 - Train Loss: 0.229860, Val Loss: 0.074176
Patience: 2/15

Epoch 98/100 - Train Loss: 0.230074, Val Loss: 0.070081
Patience: 3/15

Epoch 99/100 - Train Loss: 0.238184, Val Loss: 0.065541
New best validation loss: 0.067354

Epoch 100/100 - Train Loss: 0.237286, Val Loss: 0.061941
New best validation loss: 0.065541

Skipping test predictions, focusing on validation results only...

Converting predictions back to original scale...
Predictions shape: (70078,)
Min prediction value: 320.3759765625
Max prediction value: 1324.34326171875

Generating visualizations...
All plots will be saved to experiment directory: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS
Saved convergence plot to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/visualizations/convergence_plot_21006846.png
Length of test_actual: 70078
Length of predictions: 70078
Saved water level PNG plot to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/visualizations/water_level_station_21006846_20250525_040233.png
VINGE data is None for station 21006846
Opening plot in browser: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/visualizations/predictions_station_21006846_20250525_040233.html

Calculating anomalies...
Number of anomalies detected: 90

Validation Metrics (against original data):
  rmse: 28.454427
  mae: 13.137426
  nse: 0.985078

[2025-05-25 04:02:40] Generating diagnostic visualizations for station 21006846...
  - Creating individual residual plots...
Individual residual plots saved to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/individual_residuals
  - Creating actual vs predicted plot...
Saved actual vs predicted plot to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/actual_vs_predicted_21006846_20250525_040249.png
  - Creating error pattern heatmap...
Saved error heatmap to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/error_heatmap_21006846_20250525_040251.png
  - Creating feature importance plot...
Warning: Data contains NaN or infinite values. Cleaning data for analysis.
Saved feature importance plot to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/feature_importance_21006846_20250525_040253.png
  - Creating correlation analysis plots...
Saved correlation analysis plots to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/correlation_analysis_21006846_20250525_040316.png and /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics/error_correlation_21006846_20250525_040316.png

All diagnostic visualizations saved to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics

============================================================
EXPERIMENT CPFS COMPLETED SUCCESSFULLY!
============================================================
Results saved to: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS
  - Diagnostics: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/diagnostics
  - Anomaly Detection: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/anomaly_detection
  - Visualizations: /zhome/ff/b/147446/MasterThesis/Project_Code - CORRECT/results/Iterative model results/experiment_CPFS/visualizations
============================================================
